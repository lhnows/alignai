
### 1. 大语言模型与自然语言处理 (Large Language Models & NLP)

#### 1.1. MinosEval: Distinguishing Factoid and Non-Factoid for Tailored Open-Ended QA Evaluation with LLMs
* **摘要**: 现有大模型开放式问答（QA）评估方法未能区分事实性与非事实性问题。该研究提出 MinosEval，一种新型评估方法，它首先对问题进行分类，然后对事实性问题采用关键点计分策略，对非事实性问题采用实例感知列表排序策略。实验表明该方法更符合人类判断且更具可解释性。
* **论文链接**: `https://arxiv.org/pdf/2506.15215v1.pdf`
* **GitHub链接**: `https://github.com/johnny-fans/minoseval`

#### 1.2. ConLID: Supervised Contrastive Learning for Low-Resource Language Identification
* **摘要**: 该研究针对低资源语言识别（LID）中存在的类别不平衡和领域偏差问题，提出了一种新的监督对比学习（SCL）方法。该方法旨在学习对领域变化不敏感的语言表示，实验证明，它能有效提高模型在低资源语言跨领域测试数据上的性能。
* **论文链接**: `https://arxiv.org/pdf/2506.15304v1.pdf`
* **GitHub链接**: `https://github.com/epfl-nlp/conlid`

#### 1.3. Capturing Polysemanticity with PRISM: A Multi-Concept Feature Description Framework
* **摘要**: 当前神经网络可解释性方法假设一个神经元只编码一个概念，而忽略了普遍存在的多义性（polysemantic）现象。该研究提出 PRISM 框架，能够为多义性和单义性特征提供更细致的描述，从而更准确、更忠实地捕捉模型内部编码的行为。
* **论文链接**: `https://arxiv.org/pdf/2506.15538v1.pdf`
* **GitHub链接**: `https://github.com/lkopf/prism`

#### 1.4. SPARE: Single-Pass Annotation with Reference-Guided Evaluation for Automatic Process Supervision and Reward Modelling
* **摘要**: 为了解决大语言模型复杂推理中过程监督标注效率低、质量差的问题，该研究提出 SPARE 框架。该框架通过将生成方案的每一步与参考方案对齐，并提供明确的评估理由，实现了单遍、逐步骤的自动标注，有效提升了模型微调和奖励模型训练的效果。
* **论文链接**: `https://arxiv.org/pdf/2506.15498v1.pdf`
* **GitHub链接**: `https://github.com/ukplab/arxiv2025-spare-prm`

#### 1.5. Context-Informed Grounding Supervision
* **摘要**: 为解决大语言模型在利用外部知识时生成内容不够“接地气”的问题，该研究提出 CINGS 训练方法。该方法在训练时将相关上下文置于回复之前，并仅对回复内容计算损失，从而使模型在文本和视觉领域都表现出更强的知识 grounding 能力，有效减少了幻觉。
* **论文链接**: `https://arxiv.org/pdf/2506.15480v1.pdf`
* **GitHub链接**: `https://github.com/kaistai/cings`

#### 1.6. Semantically-Aware Rewards for Open-Ended R1 Training in Free-Form Generation
* **摘要**: 针对开放式长文本生成任务评估困难的问题，该研究提出了一个名为 PrefBERT 的评分模型。该模型能为生成内容的好坏提供明确的奖励信号，以指导模型训练。实验证明，使用 PrefBERT 作为奖励信号训练出的模型，其生成结果比使用传统指标训练的模型更符合人类偏好。
* **论文链接**: `https://arxiv.org/pdf/2506.15068v1.pdf`
* **GitHub链接**: `https://github.com/zli12321/long_form_rl`

#### 1.7. Approximating Language Model Training Data from Weights
* **摘要**: 该研究探讨了仅根据开源的模型权重来反推其训练数据的问题。研究者提出一种基于梯度的方法，能从一个大型公共语料库中筛选出与原始训练数据最匹配的子集，从而在不知道真实训练数据的情况下，用这些近似数据重新训练出性能接近原始模型的模型。
* **论文链接**: `https://arxiv.org/pdf/2506.15553v1.pdf`
* **GitHub链接**: `https://github.com/jxmorris12/reverse-training`

#### 1.8. Enhancing Hyperbole and Metaphor Detection with Their Bidirectional Dynamic Interaction and Emotion Knowledge
* **摘要**: 该研究提出一个名为 EmoBi 的框架，用于提升文本中夸张和隐喻的检测能力。该框架创新地利用了情感知识，并建立了夸张和隐喻两种修辞手法之间的双向动态交互模型，实验证明该方法在多个数据集上均显著优于基线方法。
* **论文链接**: `https://arxiv.org/pdf/2506.15504v1.pdf`
* **GitHub链接**: `https://github.com/zhengl00/emobi`

### 2. 多模态AI (Multimodal AI)

#### 2.1. Show-o2: Improved Native Unified Multimodal Models
* **摘要**: 该研究提出了改进的原生统一多模态模型 Show-o2。该模型在一个统一的视觉表示空间中，结合了自回归建模和流匹配技术，能够原生支持文本、图像和视频等多种模态的理解与生成任务，并展示了良好的可扩展性。
* **论文链接**: `https://arxiv.org/pdf/2506.15564v1.pdf`
* **GitHub链接**: `https://github.com/showlab/show-o`

#### 2.2. SonicVerse: Multi-Task Learning for Music Feature-Informed Captioning
* **摘要**: 该研究引入了一个多任务音乐描述模型 SonicVerse，它在生成音乐描述的同时，集成了对调性、人声等音乐特征的检测任务。通过这种方式，模型能够生成更丰富、更准确地反映音乐声学细节和高层属性的描述。
* **论文链接**: `https://arxiv.org/pdf/2506.15154v1.pdf`
* **GitHub链接**: `https://github.com/amaai-lab/sonicverse`

#### 2.3. COSMMIC: Comment-Sensitive Multimodal Multilingual Indian Corpus for Summarization and Headline Generation
* **摘要**: 为填补印度语种在多模态摘要研究领域的空白，该研究推出了 COSMMIC 数据集。这是一个包含九种主要印度语言的、对评论敏感的多模态语料库，它独特地整合了文章文本、图片和用户评论，旨在利用读者见解来提升摘要和标题的生成质量。
* **论文链接**: `https://arxiv.org/pdf/2506.15372v1.pdf`
* **GitHub链接**: `https://github.com/aaryansahu/cosmmic`

#### 2.4. DiscoSG: Towards Discourse-Level Text Scene Graph Parsing through Iterative Graph Refinement
* **摘要**: 针对现有文本场景图解析器难以处理多句子长描述的问题，该研究提出了篇章级文本场景图解析（DiscoSG）任务及相应的数据集。同时，研究者提出了一个名为 DiscoSG-Refiner 的迭代优化模型，它能以较低的成本生成更完整、更准确的篇章级场景图，并提升了下游视觉语言任务的性能。
* **论文链接**: `https://arxiv.org/pdf/2506.15583v1.pdf`
* **GitHub链接**: `https://github.com/shaoqlin/discosg`

#### 2.5. WikiMixQA: A Multimodal Benchmark for Question Answering over Tables and Charts
* **摘要**: 该研究推出了 WikiMixQA，一个用于评估模型对表格和图表进行跨模态推理能力的基准。该基准包含1000个多项选择题，要求模型从包含复杂布局、表格和图表的长文档中综合信息。评测结果显示，即使是顶尖的视觉语言模型，在需要从长文档中检索信息时，性能也会显著下降，凸显了该领域的挑战。
* **论文链接**: `https://arxiv.org/pdf/2506.15594v1.pdf`
* **GitHub链接**: `https://github.com/negar-foroutan/wikimixqa`

#### 2.6. SciVer: Evaluating Foundation Models for Multimodal Scientific Claim Verification
* **摘要**: 该研究推出了首个专门用于评估基础模型在多模态科学背景下验证主张能力的基准——SciVer。该基准包含3000个专家标注的科学论文样本。对21个先进多模态模型的评测显示，当前模型与人类专家之间存在巨大差距，并揭示了模型在理解和推理多模态科学文献方面的关键局限性。
* **论文链接**: `https://arxiv.org/pdf/2506.15569v1.pdf`
* **GitHub链接**: `https://github.com/qdrhhhh/sciver`

### 3. 计算机视觉 (Computer Vision)

#### 3.1. Hunyuan3D 2.1: From Images to High-Fidelity 3D Assets with Production-Ready PBR Material
* **摘要**: 该研究以 Hunyuan3D 2.1 系统为案例，提供了一份详尽的教程，指导用户如何处理3D数据、训练3D生成模型并评估其性能。该系统能够从图像生成带有生产级PBR（基于物理的渲染）材质的高保真3D资产，旨在降低3D内容创作的技术门槛。
* **论文链接**: `https://arxiv.org/pdf/2506.15442v1.pdf`
* **GitHub链接**: `https://github.com/tencent-hunyuan/hunyuan3d-2.1`

#### 3.2. One-Step Diffusion for Detail-Rich and Temporally Consistent Video Super-Resolution
* **摘要**: 针对真实世界视频超分任务中难以兼顾细节丰富度和时序一致性的问题，该研究提出了一种双 LoRA 学习（DLoRAL）范式。该方法通过训练一个一致性 LoRA 和一个细节 LoRA，并最终将它们合并到预训练的稳定扩散模型中，从而在单步扩散推理中高效地生成细节丰富且时序一致的高质量视频。
* **论文链接**: `https://arxiv.org/pdf/2506.15591v1.pdf`
* **GitHub链接**: `https://github.com/yjsunnn/dloral`

#### 3.3. Enhancing point cloud analysis via neighbor aggregation correction based on cross-stage structure correlation
* **摘要**: 为解决点云分析中邻域聚合存在的无关点干扰和特征层级鸿沟问题，该研究提出了点分布集抽象（PDSA）模块。该模块利用高维空间中的相关性来校正聚合过程中的特征分布，通过增强结构同质性来提升计算效率和鲁棒性，并在分割和分类任务中取得了显著性能提升。
* **论文链接**: `https://arxiv.org/pdf/2506.15160v1.pdf`
* **GitHub链接**: `https://github.com/agent9717/pointdistribution`

#### 3.4. ABC: Adaptive BayesNet Structure Learning for Computational Scalable Multi-task Image Compression
* **摘要**: 针对神经图像压缩（NIC）计算需求大的问题，该研究提出了一个名为 ABC 的框架。该框架通过贝叶斯网络结构学习，实现了对 NIC 所有组件计算复杂度的全面控制，能够根据设备能力、数据复杂度和下游任务需求动态调整网络结构，从而在保持压缩性能的同时实现计算可扩展性。
* **论文链接**: `https://arxiv.org/pdf/2506.15228v1.pdf`
* **GitHub链接**: `https://github.com/worldlife123/cbench_basic`

#### 3.5. Open-World Object Counting in Videos
* **摘要**: 该研究引入了一项新任务：视频中的开放世界物体计数。给定文本描述或图像示例，目标是统计视频中目标物体的所有唯一实例。为此，研究者提出了 CountVid 模型，并构建了新的 VideoCount 数据集。实验证明，该模型能够提供准确的物体计数，显著优于基线方法。
* **论文链接**: `https://arxiv.org/pdf/2506.15368v1.pdf`
* **GitHub链接**: `https://github.com/niki-amini-naieni/countvid`

#### 3.6. One-shot Face Sketch Synthesis in the Wild via Generative Diffusion Prior and Instruction Tuning
* **摘要**: 该研究提出了一种基于扩散模型的单样本（One-shot）人脸素描合成方法。该方法仅需一对照片-素描样本，通过在扩散模型上优化文本指令，即可将各种照片转换成风格一致的逼真素描。研究者还推出了一个新的基准数据集 OS-Sketch 以支持相关研究。
* **论文链接**: `https://arxiv.org/pdf/2506.15312v1.pdf`
* **GitHub链接**: `https://github.com/hanwu3125/os-sketch`

#### 3.7. MapFM: Foundation Model-Driven HD Mapping with Multi-Task Contextual Learning
* **摘要**: 该研究提出了一种名为 MapFM 的端到端模型，用于在线生成矢量化高清（HD）地图。该模型通过强大的基础模型来编码相机图像，并集成了鸟瞰图（BEV）语义分割的辅助任务，从而提供更丰富的上下文监督，最终提高了预测矢量化高清地图的准确性和质量。
* **论文链接**: `https://arxiv.org/pdf/2506.15313v1.pdf`
* **GitHub链接**: `https://github.com/livanoff/mapfm`

### 4. AI智能体系统 (AI Agent Systems)

#### 4.1. This is Your AI on Peer Pressure: An Observational Study of Inter-Agent Social Dynamics
* **摘要**: 该研究通过分析AI智能体之间的对话，发现它们会表现出与人类社会行为惊人相似的“同伴压力”动态。研究表明，简单的提问能有效打破破坏性沟通模式，恢复有意义的对话。这些社会动态而非技术限制，是决定对话质量的关键。
* **论文链接**: `https://paperswithcode.com/paper/this-is-your-ai-on-peer-pressure-an`
* **GitHub链接**: `https://github.com/im-knots/the-academy`

#### 4.2. AgentGroupChat-V2: Divide-and-Conquer Is What LLM-Based Multi-Agent System Need
* **摘要**: 针对现有大语言模型多智能体系统在架构设计和性能上的挑战，该研究提出 AgentGroupChat-V2 框架。该框架采用“分而治之”的全并行架构，将复杂任务分解为层级任务森林，并能自适应选择异构大模型组合进行协作。实验证明，该框架在处理复杂推理任务时具有显著优势。
* **论文链接**: `https://arxiv.org/pdf/2506.15451v1.pdf`
* **GitHub链接**: `https://github.com/mikegu721/agentgroupchat-v2`

#### 4.3. HeurAgenix: Leveraging LLMs for Solving Complex Combinatorial Optimization Challenges
* **摘要**: 该研究提出了 HeurAgenix，一个由大语言模型驱动的两阶段超启发式框架，用于解决组合优化问题。在第一阶段，它利用大模型演化启发式算法；在第二阶段，它根据问题状态动态选择最优算法。实验表明，该框架不仅优于现有的基于大模型的方法，还能媲美甚至超越专门的求解器。
* **论文链接**: `https://arxiv.org/pdf/2506.15196v1.pdf`
* **GitHub链接**: `https://github.com/microsoft/heuragenix`

### 5. AI安全、隐私、公平与可解释性 (AI Safety, Privacy, Fairness & Interpretability)

#### 5.1. Gender Inclusivity Fairness Index (GIFI): A Multilevel Framework for Evaluating Gender Diversity in Large Language Models
* **摘要**: 该研究提出了一个全面的性别公平性评估框架 GIFI，用以评估大语言模型处理二元及非二元性别的能力。通过对22个主流大模型的广泛评估，研究发现模型在性别包容性方面存在显著差异，并为提升模型的性别公平性提供了关键基准。
* **论文链接**: `https://arxiv.org/pdf/2506.15568v1.pdf`
* **GitHub链接**: `https://github.com/zhengyangshan/gifi`

#### 5.2. Pixel-level Certified Explanations via Randomized Smoothing
* **摘要**: 针对深度学习归因解释方法不鲁棒的问题，该研究提出了首个能够为任意黑盒归因方法提供像素级鲁棒性认证的框架。该框架使用随机平滑技术，可以保证在输入受到微小扰动时，像素重要性得分的稳定性，从而增强了解释的可信度。
* **论文链接**: `https://arxiv.org/pdf/2506.15499v1.pdf`
* **GitHub链接**: `https://github.com/alaaanani/certified-attributions`

#### 5.3. Privacy-Shielded Image Compression: Defending Against Exploitation from Vision-Language Pretrained Models
* **摘要**: 为了保护公开发布的图像不被滥用，该研究提出了一种名为 PSIC 的隐私保护图像压缩方法。该方法生成的比特流可以默认解码为保留视觉质量但能迷惑视觉语言模型的图像，同时在特定条件下又能解码为保留完整语义的原始图像，从而在图像压缩阶段实现隐私保护。
* **论文链接**: `https://arxiv.org/pdf/2506.15201v1.pdf`
* **GitHub链接**: `https://github.com/jiayinxu5499/psic`

#### 5.4. LoX: Low-Rank Extrapolation Robustifies LLM Safety Against Fine-tuning
* **摘要**: 该研究发现，已对齐的大语言模型在经过良性数据微调后其安全性仍可能被破坏，其根源在于安全关键的低秩子空间对微调非常敏感。基于此，研究者提出了一种无需训练的 LoX 方法，通过外推安全子空间来增强模型的安全鲁棒性，有效抵御了良性和恶意微调攻击。
* **论文链接**: `https://arxiv.org/pdf/2506.15606v1.pdf`
* **GitHub链接**: `https://github.com/vita-group/lox`

#### 5.5. Leaky Thoughts: Large Reasoning Models Are Not Private Thinkers
* **摘要**: 该研究揭示了大型推理模型在作为个人智能体时存在隐私泄露风险。研究发现，模型的“思考过程”（推理轨迹）而非最终输出，常常会包含用户的敏感数据，这些数据可能通过提示注入被提取或意外泄露。这表明，模型的安全性工作必须扩展到其内部思维过程，而不仅仅是最终输出。
* **论文链接**: `https://arxiv.org/pdf/2506.15674v1.pdf`
* **GitHub链接**: `https://github.com/parameterlab/leaky_thoughts`

#### 5.6. RAS-Eval: A Comprehensive Benchmark for Security Evaluation of LLM Agents in Real-World Environments
* **摘要**: 针对缺乏对大语言模型智能体在动态环境中进行安全评估的标准化基准，该研究推出了 RAS-Eval。这是一个全面的安全基准，包含80个测试用例和3802个攻击任务。评测结果揭示了当前智能体在真实世界部署中面临的严重安全漏洞和风险。
* **论文链接**: `https://arxiv.org/pdf/2506.15253v1.pdf`
* **GitHub链接**: `https://github.com/lanzer-tree/ras-eval`

### 6. 科学智能与AI医疗 (AI for Science & Healthcare)

#### 6.1. Acoustic Waveform Inversion with Image-to-Image Schrödinger Bridges
* **摘要**: 该研究将深度学习应用于声学全波形反演（FWI）。研究者提出使用条件化的图像到图像薛定谔桥（cI²SB）框架，将平滑速度模型和观测到的地震信号结合起来，以更高效率和保真度重建地下速度模型，超越了现有的基于扩散模型的方法。
* **论文链接**: `https://arxiv.org/pdf/2506.15346v1.pdf`
* **GitHub链接**: `https://github.com/stankevich-mipt/seismic_inversion_via_i2sb`

#### 6.2. Minimizing Structural Vibrations via Guided Flow Matching Design Optimization
* **摘要**: 为减少汽车、飞机等工程系统中的结构振动和噪声，该研究提出了一种基于引导流匹配的设计优化方法。该方法通过生成模型和振动预测代理模型协同工作，能够生成多样化且可制造的板状结构设计，以有效降低结构振动。
* **论文链接**: `https://arxiv.org/pdf/2506.15263v1.pdf`
* **GitHub链接**: `https://github.com/ecker-lab/optimizing_vibrating_plates`

#### 6.3. Sampling 3D Molecular Conformers with Diffusion Transformers
* **摘要**: 该研究将扩散 Transformer（DiT）应用于生成3D分子构象。研究者提出了 DiTMC 框架，通过模块化架构和新的图条件化策略，解决了将 DiT 应用于分子时面临的挑战，如处理欧几里得对称性和适应不同大小的分子，并在标准基准上达到了顶尖的精度和物理有效性。
* **论文链接**: `https://arxiv.org/pdf/2506.15378v1.pdf`
* **GitHub链接**: `https://github.com/ml4molsim/dit_mc`

#### 6.4. Privacy-Preserving Chest X-ray Classification in Latent Space with Homomorphically Encrypted Neural Inference
* **摘要**: 为保护医疗影像中的患者隐私，该研究提出一个基于同态加密（HE）的推理框架。该框架利用 VQGAN 将胸部X光片等大尺寸图像压缩到低维潜在空间，再对加密后的潜在表示进行神经网络推理，从而在保护隐私的同时显著降低计算开销。
* **论文链接**: `https://arxiv.org/pdf/2506.15258v1.pdf`
* **GitHub链接**: `https://github.com/jongdory/latent-he`

#### 6.5. Classification of Multi-Parametric Body MRI Series Using Deep Learning
* **摘要**: 针对多参数磁共振成像（mpMRI）检查中图像系列类型信息常因协议多样性或人为错误而不准确的问题，该研究提出一个基于深度学习的分类模型。该模型能准确分类8种不同的身体mpMRI系列，实验证明 DenseNet-121 模型表现最佳，准确率高且泛化能力强。
* **论文链接**: `https://arxiv.org/pdf/2506.15182v1.pdf`
* **GitHub链接**: `https://github.com/boahk/mri_classifier`

#### 6.6. Learn to Vaccinate: Combining Structure Learning and Effective Vaccination for Epidemic and Outbreak Control
* **摘要**: 该研究解决了在传播网络未知的情况下，如何通过有效接种来最小化疫情爆发持续时间的问题。研究者提出了一种新的图结构学习算法，并结合了针对有界树宽图的最优接种算法和适用于任意图的高效贪心启发式算法，通过实验验证了其有效性。
* **论文链接**: `https://arxiv.org/pdf/2506.15397v1.pdf`
* **GitHub链接**: `https://github.com/sepehr78/learn2vac`

#### 6.7. FedWSIDD: Federated Whole Slide Image Classification via Dataset Distillation
* **摘要**: 该研究为解决联邦学习（FL）在全切片图像（WSI）分类中面临的计算资源异构和隐私问题，提出了 FedWSIDD 框架。该框架利用数据集蒸馏（DD）技术，让各参与方学习并传输小而精的合成切片而非模型参数，从而在保护隐私的同时，提升了异构环境下的分类性能。
* **论文链接**: `https://arxiv.org/pdf/2506.15365v1.pdf`
* **GitHub链接**: `https://github.com/f1onae/fedwsidd`

#### 6.8. Conquering the Retina: Bringing Visual in-Context Learning to OCT
* **摘要**: 该研究探索了如何利用视觉上下文学习（VICL）来训练视网膜光学相干断层扫描（OCT）领域的通用模型。研究者提出了一个针对OCT的VICL评估协议，并对现有方法进行了广泛评测，为开发无需针对特定任务即可即时定义任务的通用医疗模型奠定了基础。
* **论文链接**: `https://arxiv.org/pdf/2506.15200v1.pdf`
* **GitHub链接**: `https://github.com/negralessio/thesis-visual-in-context-learning`

#### 6.9. DM-FNet: Unified multimodal medical image fusion via diffusion process-trained encoder-decoder
* **摘要**: 该研究提出了一种基于两阶段扩散模型的融合网络 DM-FNet，用于统一的多模态医学图像融合。该方法利用扩散过程训练的 UNet 捕捉精细特征，并设计了关键融合模块和混合损失函数，以平衡融合图像的亮度、色彩、对比度和细节，显著提升了融合图像的质量和信息密度。
* **论文链接**: `https://arxiv.org/pdf/2506.15218v1.pdf`
* **GitHub链接**: `https://github.com/hedan-11/dm-fnet`

### 7. 推荐系统 (Recommender Systems)

#### 7.1. DiscRec: Disentangled Semantic-Collaborative Modeling for Generative Recommendation
* **摘要**: 针对生成式推荐面临的“令牌-项目错位”和“语义-协同信号纠缠”两大挑战，该研究提出了 DiscRec 框架。该框架通过引入项目级位置嵌入，并使用双分支模块解耦语义和协同信号，最后通过门控机制进行融合，显著提升了生成式推荐的性能。
* **论文链接**: `https://arxiv.org/pdf/2506.15576v1.pdf`
* **GitHub链接**: `https://github.com/ten-mao/discrec`

#### 7.2. Advancing Loss Functions in Recommender Systems: A Comparative Study with a Rényi Divergence-Based Solution
* **摘要**: 该研究深入分析了推荐系统中两种常用损失函数 Softmax Loss (SL) 和 Cosine Contrastive Loss (CCL) 的优缺点，并指出 SL 对假负例敏感，而 CCL 数据利用率低。为此，研究者提出了基于 Rényi 散度的新损失函数 DrRL，它结合了两者的优点并有效缓解了其局限性，在准确性和鲁棒性上均表现更优。
* **论文链接**: `https://arxiv.org/pdf/2506.15120v1.pdf`
* **GitHub链接**: `https://github.com/cynthia-shengjia/aaai-2025-drrl`

#### 7.3. Multi-Interest Recommendation: A Survey
* **摘要**: 这是一篇关于多兴趣推荐的综述性论文。文章系统地回顾了多兴趣推荐的重要性、研究进展、解决方案、挑战和未来方向，并梳理了该领域代表性模型的技术细节，为研究人员提供了该领域的入门框架和概览。
* **论文链接**: `https://arxiv.org/pdf/2506.15284v1.pdf`
* **GitHub链接**: `https://github.com/whuir/multi-interest-recommendation-a-survey`

### 8. 机器学习：理论、方法与效率 (Machine Learning: Theory, Methods & Efficiency)

#### 8.1. Enhancing Vector Quantization with Distributional Matching: A Theoretical and Empirical Study
* **摘要**: 针对向量量化中存在的训练不稳定和码本崩溃问题，该研究指出其根本原因是特征分布与码本向量分布不匹配。研究者提出使用 Wasserstein 距离来对齐这两种分布，从而实现了近100%的码本利用率并显著减少了量化误差，其有效性得到了理论和实验的双重验证。
* **论文链接**: `https://arxiv.org/pdf/2506.15078v1.pdf`
* **GitHub链接**: `https://github.com/vq-research/wasserstein-vq`

#### 8.2. Semi-supervised Graph Anomaly Detection via Robust Homophily Learning
* **摘要**: 针对半监督图异常检测中“正常节点同质性相似”的假设在现实中不成立的问题，该研究提出了 RHO 框架。该框架通过自适应频率响应滤波器和图正态性对齐两个模块，能自适应地学习正常节点中多样的同质性模式，从而显著优于现有方法。
* **论文链接**: `https://arxiv.org/pdf/2506.15448v1.pdf`
* **GitHub链接**: `https://github.com/mala-lab/rho`

#### 8.3. Evolutionary Caching to Accelerate Your Off-the-Shelf Diffusion Model
* **摘要**: 为解决扩散模型推理速度慢的问题，该研究提出了一种名为 ECAD 的进化算法。该算法能够为现成的扩散模型自动学习高效的缓存策略，无需修改网络参数，即可在保证质量的同时显著提升推理速度，并能灵活适应不同的模型和分辨率。
* **论文链接**: `https://arxiv.org/pdf/2506.15682v1.pdf`
* **GitHub链接**: `https://github.com/aniaggarwal/ecad`

#### 8.4. All is Not Lost: LLM Recovery without Checkpoints
* **摘要**: 在去中心化节点上训练大语言模型面临节点故障导致模型部分丢失的挑战。该研究提出了 CheckFree，一种无需检查点或冗余计算的高效恢复方法。它通过用相邻阶段的加权平均值来替代故障阶段，在低中故障率下，其收敛速度优于传统方法。
* **论文链接**: `https://arxiv.org/pdf/2506.15461v1.pdf`
* **GitHub链接**: `https://github.com/gensyn-ai/checkfree`

#### 8.5. Global Ground Metric Learning with Applications to scRNA data
* **摘要**: 最优传输的效果很大程度上取决于底层地表度量（ground metric）的选择。该研究提出了一种新颖的度量学习方法，它只需分布级别的类别标签即可学习一个全局地表度量，从而能够更准确地计算最优传输距离，提升了嵌入、聚类和分类任务的性能。
* **论文链接**: `https://arxiv.org/pdf/2506.15383v1.pdf`
* **GitHub链接**: `https://github.com/damink/ggml-ot`

#### 8.6. Stable Gradients for Stable Learning at Scale in Deep Reinforcement Learning
* **摘要**: 该研究探讨了深度强化学习网络在规模扩大时性能下降的根本原因，并指出这与非平稳性和次优架构选择导致的梯度病理有关。研究者提出了一系列简单的干预措施来稳定梯度流，使得网络在不同深度和宽度下都能实现稳健的性能。
* **论文链接**: `https://arxiv.org/pdf/2506.15544v1.pdf`
* **GitHub链接**: `https://github.com/roger-creus/stable-deep-rl-at-scale`

#### 8.7. LIT-LVM: Structured Regularization for Interaction Terms in Linear Predictors using Latent Variable Models
* **摘要**: 该研究考虑线性预测器中交互项系数的估计问题。研究者假设交互项系数具有低维结构，并提出使用潜在向量来表示每个特征。这种名为 LIT-LVM 的结构化正则方法，在高维场景下比标准正则化器更能防止过拟合，并取得了更优的预测精度。
* **论文链接**: `https://arxiv.org/pdf/2506.15492v1.pdf`
* **GitHub链接**: `https://github.com/mlns-lab/lit-lvm`

#### 8.8. An Empirical Study of Bugs in Data Visualization Libraries
* **摘要**: 该研究首次对数据可视化（DataViz）库中的错误进行了全面分析，系统地研究了564个错误的症状和根本原因，并构建了分类法。研究发现，不正确的图形计算是导致绘图错误的主要原因，并探讨了利用视觉语言模型（VLM）检测这些错误的潜力。
* **论文链接**: `https://arxiv.org/pdf/2506.15084v1.pdf`
* **GitHub链接**: `https://github.com/williamlus/dataviz-lib-bugs`

#### 8.9. A Comparative Evaluation of Deep Learning Models for Speech Enhancement in Real-World Noisy Environments
* **摘要**: 该研究对三种先进的语音增强深度学习模型（Wave-U-Net, CMGAN, U-Net）在真实嘈杂环境下的性能进行了基准比较。评估发现，U-Net在噪声抑制方面表现出色，CMGAN在感知质量上领先，而Wave-U-Net则在保留说话人特征方面取得平衡，为不同应用场景提供了选型依据。
* **论文链接**: `https://arxiv.org/pdf/2506.15000v1.pdf`
* **GitHub链接**: `https://github.com/jahangirkhondkar/dl_speechenhancementtoolkit`

#### 8.10. The use of cross validation in the analysis of designed experiments
* **摘要**: 尽管文献警告不要在小型、结构化的实验设计分析中使用交叉验证（CV），但该研究通过实证发现，留一法交叉验证（LOOCV）在分析这类实验时通常是有效的。而更通用的 k-折交叉验证虽然也可能具有竞争力，但其表现并不稳定。
* **论文链接**: `https://arxiv.org/pdf/2506.14593v1.pdf`
* **GitHub链接**: `https://github.com/weeseml/cvanddoe`